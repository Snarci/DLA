{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# ! pip3 install einops\n",
    "# ! pip3 install vit_pytorch\n",
    "# ! pip3 install pandas\n",
    "# ! pip3 install scikit-learn\n",
    "# ! pip3 install albumentations\n",
    "# ! pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from vit_pytorch.vit import Transformer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird', '011.Rusty_Blackbird', '012.Yellow_headed_Blackbird', '013.Bobolink', '014.Indigo_Bunting', '015.Lazuli_Bunting', '016.Painted_Bunting', '017.Cardinal', '018.Spotted_Catbird', '019.Gray_Catbird', '020.Yellow_breasted_Chat', '021.Eastern_Towhee', '022.Chuck_will_Widow', '023.Brandt_Cormorant', '024.Red_faced_Cormorant', '025.Pelagic_Cormorant', '026.Bronzed_Cowbird', '027.Shiny_Cowbird', '028.Brown_Creeper', '029.American_Crow', '030.Fish_Crow', '031.Black_billed_Cuckoo', '032.Mangrove_Cuckoo', '033.Yellow_billed_Cuckoo', '034.Gray_crowned_Rosy_Finch', '035.Purple_Finch', '036.Northern_Flicker', '037.Acadian_Flycatcher', '038.Great_Crested_Flycatcher', '039.Least_Flycatcher', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '042.Vermilion_Flycatcher', '043.Yellow_bellied_Flycatcher', '044.Frigatebird', '045.Northern_Fulmar', '046.Gadwall', '047.American_Goldfinch', '048.European_Goldfinch', '049.Boat_tailed_Grackle', '050.Eared_Grebe', '051.Horned_Grebe', '052.Pied_billed_Grebe', '053.Western_Grebe', '054.Blue_Grosbeak', '055.Evening_Grosbeak', '056.Pine_Grosbeak', '057.Rose_breasted_Grosbeak', '058.Pigeon_Guillemot', '059.California_Gull', '060.Glaucous_winged_Gull', '061.Heermann_Gull', '062.Herring_Gull', '063.Ivory_Gull', '064.Ring_billed_Gull', '065.Slaty_backed_Gull', '066.Western_Gull', '067.Anna_Hummingbird', '068.Ruby_throated_Hummingbird', '069.Rufous_Hummingbird', '070.Green_Violetear', '071.Long_tailed_Jaeger', '072.Pomarine_Jaeger', '073.Blue_Jay', '074.Florida_Jay', '075.Green_Jay', '076.Dark_eyed_Junco', '077.Tropical_Kingbird', '078.Gray_Kingbird', '079.Belted_Kingfisher', '080.Green_Kingfisher', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '083.White_breasted_Kingfisher', '084.Red_legged_Kittiwake', '085.Horned_Lark', '086.Pacific_Loon', '087.Mallard', '088.Western_Meadowlark', '089.Hooded_Merganser', '090.Red_breasted_Merganser', '091.Mockingbird', '092.Nighthawk', '093.Clark_Nutcracker', '094.White_breasted_Nuthatch', '095.Baltimore_Oriole', '096.Hooded_Oriole', '097.Orchard_Oriole', '098.Scott_Oriole', '099.Ovenbird', '100.Brown_Pelican', '101.White_Pelican', '102.Western_Wood_Pewee', '103.Sayornis', '104.American_Pipit', '105.Whip_poor_Will', '106.Horned_Puffin', '107.Common_Raven', '108.White_necked_Raven', '109.American_Redstart', '110.Geococcyx', '111.Loggerhead_Shrike', '112.Great_Grey_Shrike', '113.Baird_Sparrow', '114.Black_throated_Sparrow', '115.Brewer_Sparrow', '116.Chipping_Sparrow', '117.Clay_colored_Sparrow', '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow', '121.Grasshopper_Sparrow', '122.Harris_Sparrow', '123.Henslow_Sparrow', '124.Le_Conte_Sparrow', '125.Lincoln_Sparrow', '126.Nelson_Sharp_tailed_Sparrow', '127.Savannah_Sparrow', '128.Seaside_Sparrow', '129.Song_Sparrow', '130.Tree_Sparrow', '131.Vesper_Sparrow', '132.White_crowned_Sparrow', '133.White_throated_Sparrow', '134.Cape_Glossy_Starling', '135.Bank_Swallow', '136.Barn_Swallow', '137.Cliff_Swallow', '138.Tree_Swallow', '139.Scarlet_Tanager', '140.Summer_Tanager', '141.Artic_Tern', '142.Black_Tern', '143.Caspian_Tern', '144.Common_Tern', '145.Elegant_Tern', '146.Forsters_Tern', '147.Least_Tern', '148.Green_tailed_Towhee', '149.Brown_Thrasher', '150.Sage_Thrasher', '151.Black_capped_Vireo', '152.Blue_headed_Vireo', '153.Philadelphia_Vireo', '154.Red_eyed_Vireo', '155.Warbling_Vireo', '156.White_eyed_Vireo', '157.Yellow_throated_Vireo', '158.Bay_breasted_Warbler', '159.Black_and_white_Warbler', '160.Black_throated_Blue_Warbler', '161.Blue_winged_Warbler', '162.Canada_Warbler', '163.Cape_May_Warbler', '164.Cerulean_Warbler', '165.Chestnut_sided_Warbler', '166.Golden_winged_Warbler', '167.Hooded_Warbler', '168.Kentucky_Warbler', '169.Magnolia_Warbler', '170.Mourning_Warbler', '171.Myrtle_Warbler', '172.Nashville_Warbler', '173.Orange_crowned_Warbler', '174.Palm_Warbler', '175.Pine_Warbler', '176.Prairie_Warbler', '177.Prothonotary_Warbler', '178.Swainson_Warbler', '179.Tennessee_Warbler', '180.Wilson_Warbler', '181.Worm_eating_Warbler', '182.Yellow_Warbler', '183.Northern_Waterthrush', '184.Louisiana_Waterthrush', '185.Bohemian_Waxwing', '186.Cedar_Waxwing', '187.American_Three_toed_Woodpecker', '188.Pileated_Woodpecker', '189.Red_bellied_Woodpecker', '190.Red_cockaded_Woodpecker', '191.Red_headed_Woodpecker', '192.Downy_Woodpecker', '193.Bewick_Wren', '194.Cactus_Wren', '195.Carolina_Wren', '196.House_Wren', '197.Marsh_Wren', '198.Rock_Wren', '199.Winter_Wren', '200.Common_Yellowthroat']\n"
     ]
    }
   ],
   "source": [
    "#read all files from the folder CUB_200_2011 and assign the subfolder as a class\n",
    "#the subfolder name is the class name\n",
    "\n",
    "path = './CUB_200_2011/images/'\n",
    "classes = os.listdir(path)\n",
    "classes.sort()\n",
    "print(classes)\n",
    "#read all files from the subfolders\n",
    "\n",
    "data = []\n",
    "for i in range(len(classes)):\n",
    "    folder = os.path.join(path,classes[i])\n",
    "    files = os.listdir(folder)\n",
    "    for j in range(len(files)):\n",
    "        data.append([classes[i],os.path.join(folder,files[j])])\n",
    "\n",
    "#convert the list to a dataframe\n",
    "df = pd.DataFrame(data,columns=['class','path'])\n",
    "df.head()\n",
    "\n",
    "N_CLASSES = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test and validation\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations for train and validation\n",
    "transform = A.Compose([\n",
    "    A.Resize(256,256),\n",
    "    ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#create the Dataset class\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.images = self.df['path'].values\n",
    "        self.classes = self.df['class'].values\n",
    "        self.classes = np.array([classes.index(i) for i in self.classes])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = self.images[idx]\n",
    "        image = plt.imread(image)\n",
    "        #image = np.transpose(image,(2,0,1))\n",
    "        #if is grayscale, convert to rgb\n",
    "        if image.shape[0] == 1:\n",
    "            image = np.repeat(image,3,0)\n",
    "        #cast to float and normalize\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0 \n",
    "        image =  transform(image=image)['image']\n",
    "        class_ = self.classes[idx]\n",
    "        class_ = torch.tensor(class_,dtype=torch.long)\n",
    "        image = image.type(torch.FloatTensor)\n",
    "        if image.shape[0] == 1:\n",
    "            image = torch.repeat_interleave(image,3,0)\n",
    "        return image,class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataloaders\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(BirdDataset(train_df),batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader = DataLoader(BirdDataset(val_df),batch_size=BATCH_SIZE,shuffle=False)\n",
    "test_loader = DataLoader(BirdDataset(test_df),batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacopo\\miniconda3\\envs\\dl_refo_project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jacopo\\miniconda3\\envs\\dl_refo_project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "from vit_pytorch.distill import DistillableViT, DistillWrapper\n",
    "\n",
    "\n",
    "teacher = resnet50(pretrained = True)\n",
    "teacher = teacher.to(device)\n",
    "\n",
    "student_vit = DistillableViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000, # TODO:This doesn't seem working well\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "student_vit = student_vit.to(device)\n",
    "\n",
    "distiller = DistillWrapper(\n",
    "    student = student_vit,\n",
    "    teacher = teacher,\n",
    "    temperature = 3,           # temperature of distillation\n",
    "    alpha = 0.5,               # trade between main loss and distillation loss\n",
    "    hard = False               # whether to use soft or hard distillation\n",
    ")\n",
    "distiller = distiller.to(device)\n",
    "\n",
    "# img = torch.randn(124, 3, 256, 256)\n",
    "# img = img.to(device)\n",
    "# labels = torch.randint(0, 16, (124,))\n",
    "# labels = labels.to(device)\n",
    "\n",
    "# loss = distiller(img, labels)\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loop\n",
    "def train(model,train_loader,val_loader,epochs=10,lr=1e-2):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_ = []\n",
    "        val_loss_ = []\n",
    "        for i,(images,classes) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            classes = classes.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # print(\"images shape: \", images.shape)\n",
    "            # print(\"classes shape: \", classes.shape)\n",
    "            loss = model(images, classes)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_.append(loss.item())\n",
    "            # #every 100 batches, print the loss\n",
    "            # if i%80 == 0:\n",
    "            #     #transfer weights from model to maebellino model\n",
    "            #     mae_bellino.load_state_dict(model.state_dict())\n",
    "            #     #get the output image\n",
    "            #     output = mae_bellino(images) \n",
    "            #     o = output[0].cpu().detach().numpy().transpose(1,2,0)\n",
    "            #     #apply relu\n",
    "            #     o = np.maximum(o,0)\n",
    "            #     o = np.minimum(o,1)\n",
    "            #     plt.imsave(f'outputs/epoch_{epoch+1}_batch_{i}.png',o)\n",
    "        train_loss.append(np.mean(train_loss_))\n",
    "        \n",
    "        # model.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     for i,(images,classes) in enumerate(val_loader):\n",
    "                \n",
    "        #         images = images.to(device)\n",
    "        #         classes = classes.to(device)\n",
    "        #         loss = model(images, classes)\n",
    "        #         val_loss_.append(loss.item())\n",
    "                \n",
    "        #     val_loss.append(np.mean(val_loss_))\n",
    "        # print(f'Epoch: {epoch+1}, Train Loss: {train_loss[-1]}, Val Loss: {val_loss[-1]}')\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss[-1]}')\n",
    "        #save the last output image on the disk\n",
    "        #save the model\n",
    "        torch.save(model.state_dict(),f'jacoExperiments/distil.pth')\n",
    "        \n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 3.2733336924496346\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory jacoExperiments does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss,val_loss \u001b[39m=\u001b[39m train(distiller, train_loader,val_loader,epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# pred = student_vit(img) # (2, 1000)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 48\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m     \u001b[39m#save the last output image on the disk\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39m#save the model\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(),\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mjacoExperiments/distil.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m train_loss,val_loss\n",
      "File \u001b[1;32mc:\\Users\\Jacopo\\miniconda3\\envs\\dl_refo_project\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jacopo\\miniconda3\\envs\\dl_refo_project\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mc:\\Users\\Jacopo\\miniconda3\\envs\\dl_refo_project\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mstr\u001b[39;49m(name)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory jacoExperiments does not exist."
     ]
    }
   ],
   "source": [
    "train_loss,val_loss = train(distiller, train_loader,val_loader,epochs=500,lr=1e-4)\n",
    "\n",
    "\n",
    "# pred = student_vit(img) # (2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DistillableViT class is identical to ViT except for how the forward pass is handled, \n",
    "# so you should be able to load the parameters back to ViT after you have completed distillation training.\n",
    "\n",
    "# TODO: It might be uselful if we want to use a custom vit\n",
    "student_vit = student_vit.to_vit()\n",
    "type(student_vit) # <class 'vit_pytorch.vit_pytorch.ViT'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
