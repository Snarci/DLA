{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "lr = 3e-4\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "re_mean_sd=False\n",
    "debug_mode=False\n",
    "image_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "images_dir = 'images/images'\n",
    "train_list = glob.glob(os.path.join(images_dir,'*/*.jpg'))\n",
    "if debug_mode:\n",
    "    # keep only the first 100 images\n",
    "    train_list = train_list[:100]\n",
    "print(f\"Number of total images: {len(train_list)}\")\n",
    "\n",
    "#split train and validation and test\n",
    "train_list, test_list = train_test_split(train_list, test_size=0.1, random_state=seed)\n",
    "train_list, val_list = train_test_split(train_list, test_size=0.1, random_state=seed)\n",
    "\n",
    "print(f\"Number of train images: {len(train_list)}\")\n",
    "print(f\"Number of validation images: {len(val_list)}\")\n",
    "print(f\"Number of test images: {len(test_list)}\")\n",
    "\n",
    "labels = [os.path.split(os.path.split(path)[0])[1] for path in train_list]\n",
    "# kkep only unique labels\n",
    "labels = list(set(labels))\n",
    "print(\"The labels are:\" ,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not debug_mode:\n",
    "    print(len(train_list))\n",
    "    random_idx = np.random.randint(1, len(train_list), size=9)\n",
    "    print(random_idx)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "    for idx, ax in enumerate(axes.ravel()):\n",
    "        img = Image.open(train_list[idx])\n",
    "        ax.set_title(labels[idx])\n",
    "        ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_mean_sd:\n",
    "    #extract mean and std from train set\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(images_dir, transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data, _ in tqdm(train_loader):\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "else:\n",
    "    mean = [0.5035, 0.4448, 0.3722]\n",
    "    std =  [0.2078, 0.1935, 0.1769]\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.augmentations.Normalize(mean=mean, std=std),\n",
    "        A.augmentations.geometric.rotate.RandomRotate90(),\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.augmentations.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.augmentations.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_dataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        # convert image to numpy array\n",
    "        img = np.array(img)\n",
    "        #if it is a grayscale image, repeat it 3 times\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        # apply transforms\n",
    "        img = self.transform(image=img)\n",
    "        img = img['image']\n",
    "        #cast to tensor\n",
    "        #if it is a grayscale image, repeat it 3 times\n",
    "\n",
    "        label = os.path.split(os.path.split(img_path)[0])[1]\n",
    "        # map label to index of labels\n",
    "        label = labels.index(label)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "train_dataset = Create_dataset(train_list, transform=train_transforms)\n",
    "val_dataset = Create_dataset(val_list, transform=val_transforms)\n",
    "test_dataset = Create_dataset(test_list, transform=test_transforms)\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sizes of train, validation and test\n",
    "print(f\"Train size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader,val_loader, epochs, output_folder):\n",
    "    # loss function with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    # optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    # scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)    \n",
    "    # training loop\n",
    "    best_accuracy = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for data, label in tqdm(train_loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_accuracy += acc / len(train_loader)\n",
    "            epoch_loss += loss / len(train_loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            for data, label in tqdm(val_loader):\n",
    "\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "                epoch_val_accuracy += acc / len(val_loader)\n",
    "                epoch_val_loss += val_loss / len(val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        filename=\"./trained_models/\"+str(output_folder)\n",
    "        # create folder if it does not exist\n",
    "        if not os.path.exists(filename):\n",
    "            os.makedirs(filename)\n",
    "        if epoch_val_accuracy > best_accuracy:\n",
    "            best_accuracy = epoch_val_accuracy\n",
    "            filename=\"./trained_models/\"+str(output_folder)+\"/best.pt\"\n",
    "            torch.save(model.state_dict(), filename)\n",
    "        filename=\"./trained_models/\"+str(output_folder)+\"/last.pt\"\n",
    "        torch.save(model.state_dict(), filename)\n",
    "    # bring train_losses and val_losses to cpu\n",
    "    train_losses = torch.stack(train_losses).cpu().detach().numpy()\n",
    "    val_losses = torch.stack(val_losses).cpu().detach().numpy()\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def test_model(model_name, model, device, test_loader):\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    print(\"Predictions: \")\n",
    "    # load the best model\n",
    "    model.load_state_dict(torch.load(str(model_name)))\n",
    "    model.eval()\n",
    "    # make predictions and extract the classificaiton report\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for data, label in tqdm(test_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(data)\n",
    "            y_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "    print(classification_report(y_true, y_pred, target_names=labels))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ora si va ad addestrare i diversi modelli proposti via mail \n",
    "#### Quello che vogliamo fare è:\n",
    " - Addestrare prima su Resnet50 senza alcun pretraining\n",
    " - Addestrare prima su Resnet50 con pretraining\n",
    " - Addestrare Resnet50 eseguendo freezing layer di convoluzione e globalpooling\n",
    " - Addestrare Resnet50 eseguendo freezing layer dei primi layer di convoluzione\n",
    " - Addestrare Resnet50 modificata senza alcun pretraining\n",
    " - Addestrare Resnet50 modificata con pretraining\n",
    " - Addestrare Resnet50 modificata eseguendo freezing layer di convoluzione e globalpooling\n",
    " - Addestrare Resnet50 modificata eseguendo freezing layer dei primi layer di convoluzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the needed libraries\n",
    "import torchvision.models as models\n",
    "from resnet import *\n",
    "from torchsummary import summary\n",
    "num_classes = len(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet50 scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = models.resnet50(weights=None)\n",
    "# change the last layer\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_from_scratch\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet50 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# change the last layer\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_from_scratch\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet50 pretrained freeze all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# change the last layer\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "#freeze all layers except the fully connected\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_pretrained_freeze_all\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# change the last layer\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "#freeze all layers except the layers from the last block\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_pretrained_freeze_softer\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = ResNet50(num_classes=num_classes)\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_custom_from_scratch\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = ResNet50(num_classes=num_classes)\n",
    "PATH = \"models/custom_resnet50.pt\"\n",
    "model.load_state_dict(torch.load(PATH), strict=True)\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_custom_pretrained\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = ResNet50(num_classes=num_classes)\n",
    "PATH = \"models/custom_resnet50.pt\"\n",
    "model.load_state_dict(torch.load(PATH), strict=True)\n",
    "#freeze all layers except the fully connected\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_custom_pretrained\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "# create model \n",
    "model = ResNet50(num_classes=num_classes)\n",
    "PATH = \"models/custom_resnet50.pt\"\n",
    "model.load_state_dict(torch.load(PATH), strict=True)\n",
    "#freeze all layers except the layers from the last block\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# print the model summary\n",
    "summary(model.to('cpu'),  (3, 224, 224), device='cpu')\n",
    "# move model to GPU if available and compile it thanks to torch 2.0\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "MODEL_PATH = \"resnet50_custom_pretrained\"\n",
    "# train the model\n",
    "train_losses, val_losses =train(model, device, train_loader, val_loader, epochs, MODEL_PATH)\n",
    "#plot the losses\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test the model\n",
    "BEST_MODEL_PATH = \"./trained_models/\"+str(MODEL_PATH)+\"/best.pt\"\n",
    "test_model(BEST_MODEL_PATH, model, device, test_loader)\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
